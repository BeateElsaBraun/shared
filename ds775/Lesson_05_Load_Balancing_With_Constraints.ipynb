{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Balancing With Contraints Example\n",
    "\n",
    "**Note: Make sure you've already read Part 1, in which we do this problem without constraints. We'll only be explaining the new bits here.**\n",
    "\n",
    "In this example we're going to show how you could use various approaches to solve a **constrained** load balancing problem. \n",
    "\n",
    "For this problem, we're talking execution times on computer processors, with total execution time on certain processors limited to a certain amount. You might see this happen when one processor needs to \"reserve\" processing cycles for some other job not in our load balancing list. \n",
    "\n",
    "We can describe it as:\n",
    "\n",
    "given a list of $n$ execution times, divide them to be executed on $k$ processors so that the total execution time on each processor is as close to the same as possible, while $y$ constrained processors are under $x$ execution time limit.\n",
    "\n",
    "There are two kinds of constraints we can implement with our metaheuristic algorithms:\n",
    "* hard constraints\n",
    "* soft constraints\n",
    "\n",
    "We'll start with hard constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hard Constraint\n",
    "A hard constraint is a constraint which rejects any solution that doesn't meet our specifications. We've seen these before.n Pyomo we used hard constraints. We can use hard constraints with some of our metaheuristics methods. We'll use hard constraints with greedy local search and simulated annealing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Constraint - Objective Function\n",
    "For a hard constraint, our objective function remains identical, too. (If you need a refresher on what the move function is doing, please see the Lesson_05_Load_Balancing notebook.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original objective function = total squared deviation of times from balanced times\n",
    "def balance_metric(assign,times,k):\n",
    "    target = sum(times)/k\n",
    "    return sum( (sum(times[assign==j])-target)**2 for j in range(k) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard Constraint - Move Function\n",
    "Our move function is where we can implement a hard constraint. We'll implement it by first completing the move, then checking to see if the new assignments meet our constraints. If they do not, we'll return the original assignments. If they do, we'll return the new assignments.\n",
    "\n",
    "To do this, we'll need to pass in two additional parameters:\n",
    "\n",
    "* conproc - the list of constrained processors\n",
    "* conmax - the list of max total processing time allowed on each constrained processor\n",
    "\n",
    "Let's look at the function first.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a move function which changes one processor assignment randomly\n",
    "def reassign_one(assign,k,conproc, conmax):\n",
    "    # pick one of the jobs and assign it to one of k processors\n",
    "    n = len(assign)\n",
    "    # choose a job and a new processor assignment\n",
    "    which_job = np.random.randint(0,n,1)[0]\n",
    "    which_proc = np.random.randint(0,k,1)[0]\n",
    "    #make a copy of the assignments\n",
    "    new_assign = assign.copy()\n",
    "    new_assign[which_job] = which_proc\n",
    "    \n",
    "    ###################\n",
    "    # NEW - Evaluate if the new assignments meet our constraint\n",
    "    over_max = True in [sum(times[new_assign==c]) > conmax[c] for c in conproc]\n",
    "    # Only return a new assignment if it meets our constraints\n",
    "    #uncomment this line to see total time on processor\n",
    "    #print('Total time on each processor (inside function):', [ sum(times[new_assign==j]) for j in range(k)])\n",
    "    if over_max == False:\n",
    "        #print('Not over max') #uncomment this line to see if it passed\n",
    "        return new_assign\n",
    "    else:\n",
    "        #print('Over max') #uncomment this line to see if it failed\n",
    "        return assign\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what that looks like with a simple problem. We'll create some sample data, and run the reassign_one() function, constraining processor 0 to a total processing time of 10. You can uncomment the print statements in the function to see what's happening inside the function, or you can just compare what goes in with what comes out below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor (going in): [12, 12, 12]\n",
      "Processor 0 Constrained to 10: [0 0 0 1 1 1 2 2 2]\n",
      "Total time on each processor (coming out): [12, 12, 12]\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "times = np.array([2,4,6,2,4,6,2,4,6])\n",
    "assign=np.array([0,0,0,1,1,1,2,2,2])\n",
    "\n",
    "# total time on each processor ... should be the same\n",
    "print('Total time on each processor (going in):', [ sum(times[assign==j]) for j in range(k)])\n",
    "#reassign one, with processor 0 constrained to 10\n",
    "new_assign = reassign_one(assign,k, [0], [10])\n",
    "print('Processor 0 Constrained to 10:', new_assign)\n",
    "print('Total time on each processor (coming out):', [ sum(times[new_assign==j]) for j in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy Local Search - Hard Constraint\n",
    "\n",
    "To implement the hard constraint in our greedy local search, we'll use our new move function. To use that, we need our two additional parameters, so we'll update our load_balance_local function to take in 2 additional parameters:\n",
    "\n",
    "* conproc - a list of the processors to constrain\n",
    "* conmax - a list of the max times on each processor.\n",
    "\n",
    "We'll also track whether the algorithm ever finds a solution that meets the constraints. It's possible with a hard constraint that we never find a solution that works.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# local search function\n",
    "def load_balance_local(times, k, max_no_improve,conproc,conmax):\n",
    "    n = len(times)\n",
    "    # starts from a random assignment to k processors\n",
    "    current_x = np.random.randint(low=0,high=k,size=n)\n",
    "    current_f = balance_metric(current_x, times, k)\n",
    "    best_x = current_x\n",
    "    best_f = current_f\n",
    "    ##########################\n",
    "    # New - track convergence\n",
    "    converged = False\n",
    "    ##########################\n",
    "    # stop search if no better x is found within max_no_improve iterations\n",
    "    num_moves_no_improve = 0\n",
    "    iterations = 0\n",
    "    while (num_moves_no_improve < max_no_improve):\n",
    "        num_moves_no_improve += 1\n",
    "        iterations += 1  # just for tracking\n",
    "        ##################################\n",
    "        # NEW - pass the extra parameters to reassign_one\n",
    "        new_x = reassign_one(current_x,k,conproc,conmax)\n",
    "        ##################################\n",
    "        new_f = balance_metric(new_x, times, k)\n",
    "        if new_f < current_f:\n",
    "            #################################\n",
    "            #NEW - track if we ever accept a solution\n",
    "            converged = True\n",
    "            #################################      \n",
    "            num_moves_no_improve = 0\n",
    "            current_x = new_x\n",
    "            current_f = new_f\n",
    "            if current_f < best_f:  \n",
    "                best_x = current_x  \n",
    "                best_f = current_f\n",
    "    return best_x, best_f, iterations, converged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run this with a small number of processors and a small number of job execution times. First let's generate some random data and see what the time on each processor would be if it loads were completely balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor, if completely balanced: 1220.6666666666667\n"
     ]
    }
   ],
   "source": [
    "# generate random job times\n",
    "np.random.seed(666) #comment this out to play with new numbers\n",
    "#we'll start with 20 execution times\n",
    "n = 30\n",
    "#we'll start with 2 processors\n",
    "k = 3\n",
    "min_time = 20\n",
    "max_time = 200\n",
    "times = np.random.randint(low=min_time, high = max_time, size = n)\n",
    "assign = np.random.randint(low=0,high=k,size=n)\n",
    "# total time on each processor\n",
    "print('Total time on each processor, if completely balanced:', sum(times)/k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running local search with constraints\n",
    "\n",
    "Let's start with setting processor 0 to be constrained to a max processing time of 1100. Run this code several times. How often do you get convergence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm found a solution that met the criteria: False\n",
      "The best assignment is [2 0 0 2 0 0 1 1 1 1 1 1 0 0 0 2 1 2 1 0 0 1 2 0 0 2 1 1 2 2]\n",
      "Total time on each processor: [1353, 1373, 936]\n",
      "The deviation from balance is 121752.66666666666\n",
      "It took 5000 iterations.\n"
     ]
    }
   ],
   "source": [
    "#####################\n",
    "# NEW: adding our 2 additional parameters to the function and one additional return variable\n",
    "#####################\n",
    "best_assign, best_f, num_iter, converged = load_balance_local(times,k,5000,[0],[1100]) \n",
    "print('The algorithm found a solution that met the criteria:', converged)\n",
    "print('The best assignment is', best_assign)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])\n",
    "print('The deviation from balance is', best_f)\n",
    "print('It took', num_iter, 'iterations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we wanted to constrain 2 of our processors? Easy! We just add to our conproc and conmax lists. This time, let's constrain processor 0 to a max time of 1200 and processor 1 to a max time of 1100. Again, run this code multiple times and see how often the algorithm converges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm found a solution that met the criteria: False\n",
      "The best assignment is [2 1 2 2 2 1 1 2 2 1 2 1 2 2 1 1 2 0 0 0 1 1 1 0 1 2 2 1 1 0]\n",
      "Total time on each processor: [749, 1391, 1522]\n",
      "The deviation from balance is 342284.6666666667\n",
      "It took 5000 iterations.\n"
     ]
    }
   ],
   "source": [
    "best_assign, best_f, num_iter, converged = load_balance_local(times,k,5000,[0,1],[1200,1100]) #adding our 2 additional parameters here\n",
    "print('The algorithm found a solution that met the criteria:', converged)\n",
    "print('The best assignment is', best_assign)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])\n",
    "print('The deviation from balance is', best_f)\n",
    "print('It took', num_iter, 'iterations.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulated Annealing - By Hand - Hard Constraints\n",
    "\n",
    "We can take the same hard constraint approach with our hand-coded simulated annealing problem. Once again, we'll add 2 parameters to our custom_simanneal function:\n",
    "\n",
    "* conproc - a list of the processors to constrain\n",
    "* conmax - a list of the max times on each processor.\n",
    "\n",
    "And once again we'll pass back a convergence variable to let us know if we ever found a solution that matched our constraints.\n",
    "\n",
    "We'll use the same set of jobs from the previous example so you can compare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The algorithm found a solution that met the criteria: False\n",
      "The best assignment is 383660.6666666667\n",
      "Total time on each processor: [1466, 1481, 715]\n",
      "The deviation from balance is 383660.6666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def custom_simanneal(times, k, max_no_improve, temp, alpha, conproc, conmax):\n",
    "    #get the length of our jobs\n",
    "    n = len(times)\n",
    "    # starts from a random assignment to k processors\n",
    "    current_x = np.random.randint(low=0,high=k,size=n)\n",
    "    current_f = balance_metric(current_x, times, k)\n",
    "    best_x = current_x\n",
    "    best_f = current_f\n",
    "    \n",
    "    #this is just for tracking\n",
    "    iterations = 1\n",
    "    trajectory = [[iterations,current_f]]\n",
    "    trajectory_best = [[iterations,best_f]]\n",
    "    ##########################\n",
    "    # New - track convergence\n",
    "    converged = False\n",
    "    ##########################\n",
    "\n",
    "    # stop search if no better x is found within max_no_improve iterations\n",
    "    num_moves_no_improve = 0\n",
    "    while (num_moves_no_improve < max_no_improve):\n",
    "        num_moves_no_improve += 1\n",
    "        iterations += 1  # just for tracking\n",
    "        ###################################\n",
    "        #NEW - add the 2 extra parameters\n",
    "        new_x = reassign_one(current_x,k, conproc, conmax)\n",
    "        ###################################\n",
    "        new_f = balance_metric(new_x, times, k)\n",
    "      \n",
    "        #determine the change in score\n",
    "        delta = new_f - current_f\n",
    "        #determine the probability of accepting this solution\n",
    "        prob = np.exp(min(delta, 0) / temp)\n",
    "        \n",
    "        #determine if we'll accept this solution\n",
    "        accept = new_f < current_f or np.random.uniform() < prob          \n",
    "        if accept:   \n",
    "            current_x = new_x\n",
    "            current_f = new_f\n",
    "            if current_f < best_f:  \n",
    "                #################\n",
    "                #New - track if we ever got a better solution than the first\n",
    "                converged = True\n",
    "                #################\n",
    "                best_x = current_x  \n",
    "                best_f = current_f\n",
    "                num_moves_no_improve = 0\n",
    "        temp *= alpha\n",
    "        iterations += 1\n",
    "        trajectory.append([iterations,current_f])\n",
    "        trajectory_best.append([iterations,best_f])        \n",
    "    return best_x, best_f, iterations, trajectory, trajectory_best,converged ####NEW: Return extra variable\n",
    "    \n",
    "\n",
    "#######\n",
    "# New - add the 2 extra parameters\n",
    "best_x, best_f, iterations, trajectory, trajectory_best, converged = custom_simanneal(times, k, 1000, 500, .99, [0],[1100])\n",
    "\n",
    "print('The algorithm found a solution that met the criteria:', converged)\n",
    "print('The best assignment is', best_f)\n",
    "print('Total time on each processor:', [ sum(times[best_x==j]) for j in range(k)])\n",
    "print('The deviation from balance is', best_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simanneal Package - Hard Constraints\n",
    "We can also use a hard constraint with the simanneal package. As a reminder, with simanneal, you don't use external functions. You add your code within the package's move and energy functions. To use a hard constraint in simanneal, you'd enforce the constraint in the **move** function, just like we did with our hand-coding.\n",
    "\n",
    "We again need our two extra variables:\n",
    "* conproc - a list of the processors to constrain\n",
    "* conmax - a list of the max times on each processor.\n",
    "\n",
    "But this time we'll pass them into the initialization function of the simanneal package.\n",
    "\n",
    "\n",
    "Let's see what that looks like.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   260.00000      28648.67    56.05%     0.00%     0:00:03     0:00:002 Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   260.00000      22858.67    55.42%     0.00%     0:00:13     0:00:003"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set is:  [0 2 1 2 1 0 2 1 1 0 1 2 0 0 0 2 1 1 0 2 1 2 0 1 2 0 1 2 0 2]\n",
      "Total time on each processor: [1100, 1280, 1282]\n",
      "The best score is: 21842.666666666664\n"
     ]
    }
   ],
   "source": [
    "#this line just imports the package\n",
    "from simanneal import Annealer\n",
    "\n",
    "#this is the line where we decide what we're calling this problem\n",
    "class loadProblem(Annealer):\n",
    "\n",
    "    # Here's where we pass extra data if we need it. We need to pass our times (jobs) variable and the number of servers (k)\n",
    "    ##############################\n",
    "    #NEW - add 2 extra parameters\n",
    "    def __init__(self, state, times, k, conproc, conmax):\n",
    "        ###############################\n",
    "        #this line makes the times accessible within the other two functions\n",
    "        self.times = times\n",
    "        self.k = k\n",
    "        ###########################\n",
    "        # New Set up 2 new variables\n",
    "        self.conproc = conproc\n",
    "        self.conmax = conmax\n",
    "        ###########################\n",
    "        #this is how we initialize - note we're calling super with the same name as above (loadProblem)\n",
    "        super(loadProblem, self).__init__(state)  # important!\n",
    "\n",
    "    def move(self):\n",
    "        \"\"\"This corresponds to our previous reassign one function\"\"\"\n",
    "        # pick one of the jobs and assign it to one of k processors\n",
    "        \n",
    "        #############################\n",
    "        #NEW - We have to COPY the state\n",
    "        assign = self.state.copy()\n",
    "        n = len(assign)\n",
    "        k = self.k\n",
    "        # choose a job and a new processor assignment\n",
    "        which_job = np.random.randint(0,n,1)[0]\n",
    "        which_proc = np.random.randint(0,k,1)[0]\n",
    "        assign[which_job] = which_proc\n",
    "        \n",
    "        #################################################\n",
    "        # NEW - hard constraint enforcement\n",
    "        over_max = True in [sum(self.times[assign==c]) > self.conmax[c] for c in self.conproc]\n",
    "        # Only update the state if it meets our requirements\n",
    "        if over_max == False:\n",
    "            #we only update the state if we've met our constraints\n",
    "            self.state = assign\n",
    "        \n",
    "    \n",
    "    def energy(self):\n",
    "        \"\"\"This corresponds to our balance_metric function\"\"\"\n",
    "        times = self.times\n",
    "        assign = self.state\n",
    "        k = self.k\n",
    "        target = sum(times)/k\n",
    "        return sum( (sum(times[assign==j])-target)**2 for j in range(k) )\n",
    "\n",
    "\n",
    "#initialize the class\n",
    "ld = loadProblem(assign, times, k, [0], [1100])\n",
    "ld.set_schedule(ld.auto(minutes=.2)) #set approximate time to find results\n",
    "\n",
    "# since our state is a numpy array, we need deepcopy\n",
    "ld.copy_strategy = \"deepcopy\" \n",
    "#this is what kicks it off\n",
    "best_assign, best_score = ld.anneal()\n",
    "\n",
    "\n",
    "\n",
    "print('The best set is: ', best_assign)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])\n",
    "print('The best score is:', best_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Simanneal evaluates the problem space before running. If your constraint is set too low, simanneal will print the first pink line, and then just hang. If you're playing with this and it gets stuck, you'll need to restart your kernel and loosen your constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft-Constraints\n",
    "As we've seen, sometimes with hard constraints you fail to get a viable solution, and we can't even get closer to a viable solution because we're rejecting any option that doesn't meet the constraint. Soft constraints fix that problem. We won't always get a solution that meets the constraint, but the algorithm will at least have a chance to get closer to an optimal solution. The Big M approach is a type of soft constraint.\n",
    "\n",
    "In the metaheuristic algorithms we're exploring, soft constraints are implemented in the objective function. Instead of rejecting a solution outright, a penalty is incorporated. For a minimization problem, a positive number is added when the constraint isn't met. For a maximization problem, a negative number is added. In our code, we're adding a multiplier to the penalty. The larger the multipler, the \"harder\" the soft constraint.\n",
    "\n",
    "Let's look at what this would look like with a hand-solved problem.\n",
    "\n",
    "We'll keep our original objective function (balanced_metric), but we'll add a new wrapper function (balanced_metric_constrained). This one will take in 2 additional parameters:\n",
    "* a list of constrained processors\n",
    "* a list of the max times on each processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# constrained objective function = total squared deviation of times from balanced times, providing a penalty for constraints\n",
    "def balance_metric_constrained(assign,times,k,conproc,conmax):\n",
    "    #sum the unconstrained processor deviation\n",
    "    dev_uncon = balance_metric(assign,times,k)\n",
    "    #sum the constrained processors\n",
    "    penalty_multiplier = 5\n",
    "    dev_penalty = penalty_multiplier * sum( max(sum(times[assign==c])-conmax[c],0)**2 for c in conproc )\n",
    "\n",
    "    return dev_uncon + dev_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Soft Constraint\n",
    "\n",
    "We'll test our two functions with some hand-coded assignments. We'll use 9 jobs on 3 processors. First we'll look at them as an unconstrained, perfectly balanced problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor: [12, 12, 12]\n",
      "Unconstrained Balance Metric: 0.0\n"
     ]
    }
   ],
   "source": [
    "#testing perfectly balanced unconstrained\n",
    "k = 3\n",
    "times = np.array([2,4,6,2,4,6,2,4,6])\n",
    "assign=np.array([0,0,0,1,1,1,2,2,2])\n",
    "\n",
    "# total time on each processor ... should be the same\n",
    "print('Total time on each processor:', [ sum(times[assign==j]) for j in range(k)])\n",
    "#print the original balance metric\n",
    "print('Unconstrained Balance Metric:', balance_metric(assign,times,k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add some constraints. Note that neither our times nor assignments are changing. But, we're essentially changing the target for some of our processors. We're going to set processor 0 to a max limit of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor (has not changed): [12, 12, 12]\n",
      "Constrained Balance Metric: 20.0\n"
     ]
    }
   ],
   "source": [
    "# total time on each processor has not changed\n",
    "print('Total time on each processor (has not changed):', [ sum(times[assign==j]) for j in range(k)])\n",
    "#Constrain processor 1 to 10\n",
    "print('Constrained Balance Metric:', balance_metric_constrained(assign,times,k,[0],[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the constraint in place, what was a completely balanced solution no longer looks so great. What would happen if we switch our assignments around some?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor (has changed): [10, 14, 12]\n",
      "Balance Metric without constraints 8.0\n",
      "Constrained Balance Metric: 8.0\n"
     ]
    }
   ],
   "source": [
    "#new assignments\n",
    "assign=np.array([1,0,0,1,1,1,2,2,2])\n",
    "print('Total time on each processor (has changed):', [ sum(times[assign==j]) for j in range(k)])\n",
    "\n",
    "#check the unconstrained balance metric\n",
    "print('Balance Metric without constraints', balance_metric(assign,times,k))\n",
    "#check the constrained balance metric\n",
    "print('Constrained Balance Metric:', balance_metric_constrained(assign,times,k,[0],[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've met our constraint, so our unconstrained and constrained balance metrics match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simanneal Package - Soft Constraint\n",
    "With simanneal, instead of adding our hard constraint to the move() function, we'd add our soft constraint to the energy() function. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line just imports the package\n",
    "from simanneal import Annealer\n",
    "\n",
    "#this is the line where we decide what we're calling this problem\n",
    "class loadProblem(Annealer):\n",
    "\n",
    "    # Here's where we pass extra data if we need it. We need to pass our times (jobs) variable and the number of servers (k)\n",
    "    ##############################\n",
    "    #NEW - add 2 extra parameters\n",
    "    def __init__(self, state, times, k, conproc, conmax):\n",
    "        ###############################\n",
    "        #this line makes the times accessible within the other two functions\n",
    "        self.times = times\n",
    "        self.k = k\n",
    "        ###########################\n",
    "        # New Set up 2 new variables\n",
    "        self.conproc = conproc\n",
    "        self.conmax = conmax\n",
    "        ###########################\n",
    "        #this is how we initialize - note we're calling super with the same name as above (loadProblem)\n",
    "        super(loadProblem, self).__init__(state)  # important!\n",
    "\n",
    "    def move(self):\n",
    "        \"\"\"This corresponds to our previous reassign one function\"\"\"\n",
    "        # pick one of the jobs and assign it to one of k processors\n",
    "        ##################################\n",
    "        #NEW - back to just changing the state directly\n",
    "        assign = self.state\n",
    "        n = len(assign)\n",
    "        k = self.k\n",
    "        # choose a job and a new processor assignment\n",
    "        which_job = np.random.randint(0,n,1)[0]\n",
    "        which_proc = np.random.randint(0,k,1)[0]\n",
    "        assign[which_job] = which_proc\n",
    "\n",
    "        \n",
    "    \n",
    "    def energy(self):\n",
    "        \"\"\"This corresponds to our balance_metric function\"\"\"\n",
    "        times = self.times\n",
    "        assign = self.state\n",
    "        k = self.k\n",
    "        conproc = self.conproc\n",
    "        conmax = self.conmax\n",
    "        ############################################\n",
    "        #NEW - determing the energy and assign a penalty\n",
    "        target = sum(times)/k\n",
    "        #sum the unconstrained processor deviation\n",
    "        dev_uncon = sum( (sum(times[assign==j])-target)**2 for j in range(k) )\n",
    "        #sum the constrained processors\n",
    "        penalty_multiplier = 5\n",
    "        dev_penalty = penalty_multiplier * sum( max(sum(times[assign==c])-conmax[c],0)**2 for c in conproc )\n",
    "\n",
    "        return dev_uncon + dev_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's generate some more test data and run our soft constraint version of simanneal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor, if completely balanced: 1220.6666666666667\n"
     ]
    }
   ],
   "source": [
    "# generate random job times\n",
    "np.random.seed(666) #comment this out to play with new numbers\n",
    "#we'll start with 20 execution times\n",
    "n = 30\n",
    "#we'll start with 2 processors\n",
    "k = 3\n",
    "min_time = 20\n",
    "max_time = 200\n",
    "times = np.random.randint(low=min_time, high = max_time, size = n)\n",
    "assign = np.random.randint(low=0,high=k,size=n)\n",
    "# total time on each processor\n",
    "print('Total time on each processor, if completely balanced:', sum(times)/k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With completely balanced loads, we'd have 1220-ish on each processor. We'll set processor 0's constraint to 1100. Run this code several times. How often do you meet the constraint? How balanced does the workload seem compared to our hard constraint version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   450.00000      17054.67    33.25%     0.00%     0:00:03    -1:59:591 Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   450.00000      17184.67    34.52%     0.16%     0:00:13     0:00:001"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best set is:  [0 1 0 0 1 1 1 2 1 1 1 2 2 2 2 2 2 1 1 0 0 0 1 2 0 0 2 2 2 0]\n",
      "Total time on each processor: [1128, 1266, 1268]\n",
      "The best score is: 16802.666666666668\n"
     ]
    }
   ],
   "source": [
    "#initialize the class\n",
    "ld = loadProblem(assign, times, k, [0], [1100])\n",
    "ld.set_schedule(ld.auto(minutes=.2)) #set approximate time to find results\n",
    "\n",
    "# since our state is a numpy array, we need deepcopy\n",
    "ld.copy_strategy = \"deepcopy\" \n",
    "#this is what kicks it off\n",
    "best_assign, best_score = ld.anneal()\n",
    "\n",
    "\n",
    "\n",
    "print('The best set is: ', best_assign)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])\n",
    "print('The best score is:', best_score) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Genetic Algorithm with DEAP - Soft Constraints\n",
    "\n",
    "Again with DEAP we'll do a soft constraint in our energy function. This requires a few small, but important changes. First, the things that stay the same. \n",
    "* Our create_individual() function\n",
    "* Our custom_ga() function\n",
    "\n",
    "Neither of these change at all and we can just copy/paste the code from the load balance without constraints example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No changes to this function\n",
    "def create_individual(k,n):\n",
    "    current_x = np.random.randint(low=0,high=k,size=n)\n",
    "    return current_x.tolist() #this converts our np array back to a list\n",
    "\n",
    "\n",
    "# no changes here, call this to execute the genetic algorithm\n",
    "def customGA(in_toolbox,in_tools,in_stats,pop_size, cx_prob, mut_prob, max_gen, max_no_improve):\n",
    "\n",
    "    pop = in_toolbox.population(n=pop_size)\n",
    "    logbook = in_tools.Logbook()\n",
    "    hof = in_tools.HallOfFame(1)\n",
    "\n",
    "    # Evaluate the entire population\n",
    "    fitnesses = list(map(in_toolbox.evaluate, pop))\n",
    "    for ind, fit in zip(pop, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    hof.update(pop)\n",
    "    best_val = hof[0].fitness.values\n",
    "    num_no_improve = 0\n",
    "    generation = 0\n",
    "\n",
    "    while num_no_improve < max_no_improve and generation < max_gen:\n",
    "\n",
    "        # Select the next generation individuals\n",
    "        selected = in_toolbox.select(pop, len(pop))\n",
    "        # Clone the selected individuals\n",
    "        offspring = list(map(in_toolbox.clone, selected))\n",
    "\n",
    "        # Apply crossover and mutation on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < cx_prob:\n",
    "                in_toolbox.mate(child1, child2)\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < mut_prob:\n",
    "                in_toolbox.mutate(mutant)\n",
    "                del mutant.fitness.values\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(in_toolbox.evaluate, invalid_ind)\n",
    "        num_evals = 0\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            num_evals += 1\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # The population is entirely replaced by the offspring\n",
    "        pop[:] = offspring\n",
    "        \n",
    "        # track the best value and reset counter if there is a change\n",
    "        hof.update(pop)\n",
    "        curr_best_val = hof[0].fitness.values[0]\n",
    "        num_no_improve += 1\n",
    "        if curr_best_val != best_val:\n",
    "            best_val = curr_best_val\n",
    "            num_no_improve = 0\n",
    "\n",
    "        # record stats\n",
    "        record = in_stats.compile(pop)\n",
    "        logbook.record(gen=generation, evals=num_evals, **record)\n",
    "\n",
    "        # increment generation\n",
    "        generation += 1\n",
    "\n",
    "    best_x = list(hof[0])\n",
    "\n",
    "    return best_val, best_x, logbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our balance_metric_tuple function does need to be updated. We need to take in the 2 additional parameters (do you have these down yet?):\n",
    "* conproc - a list of constrained processors\n",
    "* conmax - a list of the max times on each processor\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3058021.6666666665,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# objective function = total squared deviation of times from balanced times\n",
    "def balance_metric_tuple(assign,times,k,conproc, conmax):\n",
    "    #make the list a numpy array\n",
    "    assign_np = np.array(assign)\n",
    "    ## call the balance_metric function\n",
    "    metric = balance_metric_constrained(assign_np, times, k, conproc, conmax)\n",
    "    return (metric, ) #note that we're returning a tuple\n",
    "\n",
    "#let's test this function\n",
    "balance_metric_tuple(assign,times,k, [0], [10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only other thing we'll need to change is how we set up our evaluate function. Most of this code is identical to what you've seen before. Note the one changed line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Best Result 1691209.6666666667\n",
      "Total time on each processor: [289, 1686, 1687]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from functools import partial\n",
    "\n",
    "creator.create(\"FitnessLoad\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessLoad)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"assignments\",create_individual,k,n)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.assignments)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "###############################\n",
    "#NEW - this line needs additional parameters\n",
    "###############################\n",
    "toolbox.register(\"evaluate\", balance_metric_tuple, times=times, k=k, conproc=[0], conmax=[10])\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) \n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low = 0, up = k-1, indpb=0.1)\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "# define search parameters\n",
    "pop_size = 200\n",
    "crossover_prob = 0.3\n",
    "mutation_prob = 0.5\n",
    "max_gen = 2000\n",
    "max_no_improve = 200\n",
    "\n",
    "# get solution\n",
    "best_balance, best_assign, log = customGA(toolbox,tools,stats, pop_size, crossover_prob, mutation_prob,\n",
    "                                     max_gen, max_no_improve)\n",
    "\n",
    "print('Genetic Algorithm Best Result', best_balance)\n",
    "print('Total time on each processor:', [ sum(times[np.array(best_assign)==j]) for j in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increasing Problem Size\n",
    "\n",
    "We used a very small problem to demonstrate each of the methods above. Now it's time to create a much larger problem and see how our algorithms perform. \n",
    "\n",
    "We'll also set conproc and conmax to constrain 2 of our 10 processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time on each processor, if completely balanced: 11422.3\n"
     ]
    }
   ],
   "source": [
    "####################################\n",
    "# Setting up a new bigger problem\n",
    "####################################\n",
    "n = 1000\n",
    "k = 10\n",
    "#we're going to set some min/max times here for the jobs\n",
    "min_time = 20\n",
    "max_time = 200\n",
    "#randomly generate some jobs\n",
    "times = np.random.randint(low=min_time, high = max_time, size = n)\n",
    "\n",
    "# total time on each processor\n",
    "print('Total time on each processor, if completely balanced:', sum(times)/k)\n",
    "\n",
    "conproc = [0,1]\n",
    "conmax=[8000,8000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "Let's see what our baseline deviation from balanced loads is with a size this large. (Note, there's randomness here and some algorithms set their own baseline. But this should give us a general idea.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with random assignments: 14584898.099999998\n"
     ]
    }
   ],
   "source": [
    "#get the baseline\n",
    "baseline = balance_metric(np.random.randint(low=0,high=k,size=n),times,k)\n",
    "print('Baseline with random assignments:', baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greedy local search\n",
    "The only parameter we can fiddle with in our greedy local search is how many iterations we're willing to go with no improvement. Try changing the 5000 number to see if it gets better results\n",
    "\n",
    "* max_no_improve = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greedy Local Search best result: 14953446.099999998\n",
      "The algorithm found a solution that met the criteria: False\n",
      "Total time on each processor: [11869, 11878, 10088, 10630, 13558, 12060, 9668, 12811, 9975, 11686]\n"
     ]
    }
   ],
   "source": [
    "#### Greedy Local Search #####\n",
    "#####################\n",
    "#Parameters\n",
    "max_no_improve = 5000\n",
    "#####################\n",
    "best_assign, best_f, num_iter, converge = load_balance_local(times,k,max_no_improve,conproc,conmax)\n",
    "print('Greedy Local Search best result:', best_f)\n",
    "print('The algorithm found a solution that met the criteria:', converged)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Simulated Annealing\n",
    "For our custom simulated annealing, we can tweak the following parameters:\n",
    "* max_no_improve = 1000\n",
    "* temp = 500\n",
    "* alpha = .99 \n",
    "\n",
    "Try tweaking these parameters to see if you can get a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Simulated Annealing best result: 10658776.1\n",
      "The algorithm found a solution that met the criteria: False\n",
      "Total time on each processor: [9874, 11557, 12010, 10912, 11250, 13744, 11432, 10596, 12300, 10548]\n"
     ]
    }
   ],
   "source": [
    "#### Custom Simulated Annealing ####\n",
    "#####################\n",
    "#Parameters\n",
    "max_no_improve = 1000\n",
    "temp = 500 \n",
    "alpha = .99\n",
    "#####################\n",
    "\n",
    "\n",
    "best_x, best_f, iterations, trajectory, trajectory_best, converge = custom_simanneal(times, k, max_no_improve, temp, alpha, conproc, conmax)\n",
    "print('Custom Simulated Annealing best result:', best_f)\n",
    "print('The algorithm found a solution that met the criteria:', converged)\n",
    "print('Total time on each processor:', [ sum(times[best_x==j]) for j in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simanneal Package\n",
    "The only parameter you can tweak in the simanneal package is how long you're willing to wait. Try changing that to see if you can get a better result.\n",
    "* wait_time = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   200.00000   23424942.10     9.70%     0.00%     0:00:27    -1:59:5059 Temperature        Energy    Accept   Improve     Elapsed   Remaining\n",
      "   200.00000   23424881.10    12.29%     0.29%     0:00:14     0:00:0003"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simanneal Package best result 23424881.1\n",
      "Total time on each processor: [8685, 8680, 12102, 12109, 12104, 12104, 12093, 12116, 12111, 12119]\n"
     ]
    }
   ],
   "source": [
    "#### Simanneal Package ####\n",
    "#####################\n",
    "#Parameters\n",
    "wait_time = .2\n",
    "#####################\n",
    "\n",
    "assign = np.random.randint(low=0,high=k,size=n)\n",
    "ld = loadProblem(assign, times, k, conproc, conmax)\n",
    "ld.set_schedule(ld.auto(minutes=wait_time)) \n",
    "ld.copy_strategy = \"deepcopy\" \n",
    "best_assign, best_score = ld.anneal()\n",
    "print('Simanneal Package best result', best_score)\n",
    "print('Total time on each processor:', [ sum(times[best_assign==j]) for j in range(k)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEAP Genetic Algorithm\n",
    "DEAP has a lot of parameters to tweak. Try tweaking some of the following to see if you can get a better result.\n",
    "\n",
    "* pop_size = 200\n",
    "* crossover_prob = 0.3\n",
    "* mutation_prob = 0.5\n",
    "* max_gen = 2000\n",
    "* max_no_improve = 200\n",
    "\n",
    "(*Note*: that we need to repeat a lot of code when we're changing the problem space with DEAP. DEAP hard-codes the k and n in our functions when we set it up, so we need to essentially start from scratch. We've included all the necessary code without comments in the cell below.) \n",
    "\n",
    "**Warning**: This code will be slow to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genetic Algorithm Best Result 23434999.1\n",
      "Total time on each processor: [8671, 8694, 12168, 12129, 12078, 12098, 12115, 12046, 12104, 12120]\n"
     ]
    }
   ],
   "source": [
    "#### DEAP Genetic Algorithm ####\n",
    "####################\n",
    "#Parameters\n",
    "pop_size = 200\n",
    "crossover_prob = 0.3\n",
    "mutation_prob = 0.5\n",
    "max_gen = 2000\n",
    "max_no_improve = 200\n",
    "#####################\n",
    "\n",
    "\n",
    "###################################\n",
    "# Leave everything below here alone\n",
    "###################################\n",
    "\n",
    "# how we create our individuals\n",
    "def create_individual(k,n):\n",
    "    current_x = np.random.randint(low=0,high=k,size=n)\n",
    "    return current_x.tolist() #this converts our np array back to a list\n",
    "\n",
    "# objective function = total squared deviation of times from balanced times\n",
    "def balance_metric_tuple(assign,times,k,conproc, conmax):\n",
    "    #make the list a numpy array\n",
    "    assign_np = np.array(assign)\n",
    "    ## call the balance_metric function\n",
    "    metric = balance_metric_constrained(assign_np, times, k, conproc, conmax)\n",
    "    return (metric, ) #note that we're returning a tuple\n",
    "\n",
    "creator.create(\"FitnessLoad\", base.Fitness, weights=(-1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessLoad)\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register(\"assignments\",create_individual,k,n)\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.assignments)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"evaluate\", balance_metric_tuple, times=times, k=k, conproc=conproc,conmax=conmax)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) \n",
    "toolbox.register(\"mutate\", tools.mutUniformInt, low = 0, up = k-1, indpb=0.1)\n",
    "stats = tools.Statistics(key=lambda ind: ind.fitness.values)\n",
    "stats.register(\"avg\", np.mean)\n",
    "stats.register(\"std\", np.std)\n",
    "stats.register(\"min\", np.min)\n",
    "stats.register(\"max\", np.max)\n",
    "\n",
    "# get solution\n",
    "best_balance, best_assign, log = customGA(toolbox,tools,stats, pop_size, crossover_prob, mutation_prob,\n",
    "                                     max_gen, max_no_improve)\n",
    "\n",
    "print('Genetic Algorithm Best Result', best_balance)\n",
    "print('Total time on each processor:', [ sum(times[np.array(best_assign)==j]) for j in range(k)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.696px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
